\subsubsection*{Desarrollo}
\textbf{Estructuras de Datos}

Para manejar las imágenes implementamos la clase Imagen, en la cual almacenamos los parámetros de cada imagen (la altura y ancho originales de la imagen, el nombre del archivo, id de la clase y los bytes de la imagen propiamente dicha en formato vector de unsigned char).
Para la lectura de los archivos de imágenes utilizamos las librerías provistas por la cátedra.
Las imágenes a medida que se leen se almacenan en la estructura que denominamos baseDeDatos, la cual consiste de un vector de Imagen.
Para la implementación de las funciones necesarias para PCA trabajamos con dos estructuras principales: doubleVector que como lo indica su nombre consiste de un vector de doubles donde almacenamos cada imagen vectorizada, y la otra estructura es dobleMatrix que usamos para almacenar todas las imágenes vectorizadas (una por fila), con el objetivo de poder operar matricialmente con ellas dentro de las funciones de una forma práctica.

\textbf{KNN}

El KNN vendría a ser de algúna forma el centro de nuestro algoritmo, ya que es donde se toma la decisión cde cual es el sujeto de la base de entrenamiento que se corresponde con la imagen que elegimos para testear.

Esto lo hicimos calculando la distancia euclídea entre el elemento a testear y todos los elementos de la base de entrenamiento, guardandonos la distancia resultante y el sujeto al que pertenecía cada imagen de la base. Luego necesitabamos tener estos datos ordenados de acuerdo a las distancias obtenidas. Con los datos ya ordenados lo único que nos quedaba por hacer era tomar los id correspondientes a las k menores distancias y finalmente calcular la moda, es decir, cuál de esos id aparecía más veces. Para eso creamos un vector inicializado en cero donde en cada subindice i sumamos la cantidad de apariciones del sujeto i entre los k más cercanos a la imagen testeada, y por último buscando el id de este vector que contenga el elemento más grande obtenemos el resultado que buscabamos, es decir, el id que "matchea" mejor con la imagen que testeamos según nuestros métodos. 

Una de las dificultades con las que nos encontramos en la implementación de esta función debido a que en primer lugar fue pensada para trabajar sobre una base de datos de imágenes, entonces al usar el método PCA + KNN nos encontramos con que al hacer KNN recibíamos una doubleMatrix en lugar que una baseDeDatos.
Para resolverlo decidímos simplemente crear nuevas funciones KNN que permitieran hacer el calculo sobre una doubleMatrix. Estas funciones son análogas a las anteriores, la mayor diferencia está en cómo hicimos para identificar el sujeto al que correspondía cada imágen.

Mientras en el KNN (sin PCA) al estar trabajando con elementos de tipo \textit{imagen} podíamos acceder directamente al \textit{id} de cada una (es decir a qué sujeto pertenecía), al implementar KNN con PCA para resolver esto aprovechamos el dato de que tanto en la matriz resultante luego de aplicar PCA como la matriz de entrenamiento original tienen la misma cantidad de filas y, más aún, la fila \textit{i} de ambas matrices corresponde a una misma imagen.
Luego lo que hicimos fue, una vez obtenida cuál era la fila dentro de la doubleMatrix de alguna de las k imágenes más cercanas, ver a que id correspondía la imagen que se encontraba en ese mismo lugar en la base de entrenamiento original. 


\textbf{PCA}

La implementación del método PCA consta de varios pasos:
En un primer paso se arma la matriz X (de tipo doubleMatrix) que contiene los bytes de datos de las imágenes vectorizadas. Esta matriz se debería usar para calcular la matriz de covarianza de la muestra, que luego debería ser diagonalizada para obtener los autovectores que permiten hacer una cambio de base de la muestra dejando las variables (valores de las columnas) lo más independientes posible.
La matriz de covarianza se calcula haciendo el producto matricial $X{t} * X$. Considerando que la cantidad de columnas de la matriz $X$ es igual a la cantidad de pixeles de una imagen, el resultado del producto es una matriz que fácilmente puede volverse gigantesca como para poder operar con ella, de manera que resulta muy costoso en términos de uso de la memoria del equipo. Con el objeto de atenuar este problema, en lugar de calcular los autovectores de la matriz $X{t} * X$, lo hacemos con $X * X{t}$. Estas matrices comparten los mismos autovalores y sus autovectores puede ser calculados unos en función de los otros. Si bien la implementación se complicó porque tuvimos que programar la conversión de los autovectores, la ventaja que obtuvimos es que operamos con matrices de menor dimensión, puesto que la cantidad de imágenes (filas de X) es en nuestro caso notablemente menor que la cantidad de pixeles de cada imagen (columnas de X).
La matriz $X * X{t}$ es una matriz simétrica, en un principio nos planteamos la posibilidad de usar alguna estrategia de almacenamiento que aprovechara esta condición para ahorrar memoria, pero en este caso decidimos no hacerlo y tratarla como una matriz común para simplificar la implementación, sin embargo en caso de una implemantación real donde sea crítico el uso del espacio debería considerarse seriamente esta opción.

\textbf{Método de la potencia:} El método de la Potencia necesita para la iteración de un vector $x$ que inicialmente contiene un valor arbitrario, el cual decidimos generar de forma aleatoria. Durante el testeo de las funciones observamos que corridas sucesivas efectuadas con las mismas imágenes de entrada producían diferentes resultados en los autovectores generados. Las diferencias se observan en los decimales menos significativos. La hipótesis es que estas diferencias se producen por utilizar el vector inicial generado de manera aleatoria. Si bien esta forma de generarlo sirvió muy bien a la hora de calcular los autovalores y autovectores de la matriz de covarianza, en una situación donde se requiera una gran precisión podría ser útil utilizar algún mecanismo que promedie los resultados obtenidos.
En el método de Deflación pudimos observar que al buscar autovalores y autovectores, las componentes principales tienen una convergencia más veloz, arribándose a un resultado preciso en pocas iteraciones del método de Potencia. A medida que se calculan mayor cantidad de componentes, la convergencia del método de Potencia se hace notoriamente más lenta y por momentos parecía que no había convergencia cuando en realidad sí la había. Esto nos llevó a utilizar dos criterios de parada para el cálculo de cada autovalor: en una primera instancia usamos una cantidad de iteraciones $n$ pidiendo una variación precisa entre los resultados de dos iteraciones sucesivas; si al cabo de esas $n$ iteraciones no llegamos a una convergencia, continuamos iterando hasta $10*n$ iteraciones más pero aceptando una diferencia algo mayor.


\textbf{Kfold (Cross-validation)}
Decidimos utilizar 5-fold.
La determinación del valor de $k$ la realizamos teniendo en cuenta los siguientes factores:
\\1) Al realizar la partición de la base de datos en datos de entrenamiento y datos de tetst queríamos que cada clase estuviera representada en una proporción similar, o sea que la selección fuera balanceada. Si bien al principio habíamos pensado hacer la partición de forma aleatoria, esto hubiera podido llevar a situaciones como por ejemplo tener en la base de entrenamiento todos los elementos de una clase y muy pocos de otra con lo cual el entrenamiento sería sesgado favoreciendo a la clase con más representantes. Por otro lado a la hora de testear podría no haber elementos de esa clase que no hubieran sido usados para entrenar con lo cual se invalidarían los resultados. Contrariamente los parámetros elegidos podrían no ser adecuados para la clase con menos representantes, con lo cual el reconocimientos de elementos pertenecientes a esa clase sería deficiente.

2) Teniendo en cuenta el punto anterior los posibles $k$ elegibles se reducen a los divisores de la cantidad de imágenes de cada clase. Siendo en el nuestro caso de 10 imágenes por clase los posibles valores son: 1, 2, 5 y 10. El 1 no tiene sentido en la práctica ya que equivale a no tener datos de entrenamiento. El 10 supone que queda solo un representante de cada clase para testear, entonces si la imagen que usamos para testear posee algúna anormalidad respecto de las otras de su clase afectaría negativamente nuestros resultados, es decir, nuestro resultado sería muy sensible a outsiders y poco robusto. En el caso de 2, estaríamos usando la mitad de los datos para entrenar y la mitad de los datos para testear y tratándose de una base de datos relativamente chica (con pocos representantes de cada clase) consideramos que tendríamos poca variedad de datos de entrenamiento. En el caso de $k$=5, estaríamos considerando dos imágenes de cada clase para testear y ocho para entrenar. De todas las posibilidades, nos pareció la más adecuada porque nos da una cantidad relativamente grande de datos de entrenamiento y más de una imagen para testear. 
